{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League of Legends Early Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import partial\n",
    "from json import load\n",
    "from os import listdir, remove\n",
    "from os.path import expanduser, isfile, join\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_indicator_from_teams(key: str, match_details: dict) -> int:\n",
    "    indicator = 0\n",
    "    for team in match_details['teams']:\n",
    "        if team['teamId'] == 100:\n",
    "            indicator -= team[key]\n",
    "        else:\n",
    "            indicator += team[key]\n",
    "    return indicator\n",
    "\n",
    "def _extract_participant_stat(aggregator: callable, key: str, match_details: dict) -> int:\n",
    "    blue = aggregator(\n",
    "        participant['stats'][key] if key in participant['stats'] else 0\n",
    "        for participant in match_details['participants']\n",
    "        if participant['teamId'] == 100)\n",
    "\n",
    "    red = aggregator(\n",
    "        participant['stats'][key] if key in participant['stats'] else 0\n",
    "        for participant in match_details['participants']\n",
    "        if participant['teamId'] == 200)\n",
    "    \n",
    "    return red-blue\n",
    "\n",
    "def _extract_participant_timeline_key(team_id: int, lane: str, key: str, frame: str, match_details: dict):\n",
    "    '''\n",
    "    - team_id (int): Possible values are 100 (blue)\n",
    "        and 200 (red).\n",
    "\n",
    "    - lane (str): Possible values are 'MIDDLE', 'TOP',\n",
    "        'JUNGLE' and 'BOTTOM'.\n",
    "\n",
    "    - key (str): Possbile values are 'goldPerMinDeltas',\n",
    "        'creepsPerMinDeltas', 'xpPerMinDeltas' and\n",
    "        'damageTakenPerMinDeltas'\n",
    "\n",
    "    - frame (str): Possible values are '0-10', '10-20',\n",
    "        '20-30' and '30-end'.\n",
    "\n",
    "    - match_details (dict): whole dictionary of parse\n",
    "        match json.\n",
    "    '''\n",
    "    metric = 0.0  # sum because two players are bottom\n",
    "\n",
    "    for participant in match_details['participants']:\n",
    "        is_lane = participant['timeline'][0]['lane'] == lane\n",
    "        is_team = participant['teamId'] == team_id\n",
    "        \n",
    "        if is_lane and is_team:\n",
    "            metric += participant['timeline'][key][frame]\n",
    "            \n",
    "    return metric\n",
    "\n",
    "def extract_red_win(match_details: dict) -> bool:\n",
    "    team = match_details['teams'][0]\n",
    "    \n",
    "    if team['teamId'] == 100:  # blue\n",
    "        if team['win'] == 'Win':\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:  # red\n",
    "        if team['win'] == 'Win':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "team_to_text = {100: 'blue', 200: 'red'}\n",
    "        \n",
    "def generate_participant_timeline_extractors(team_ids: (int,), lanes: (str,), keys: (str,), frames: (str,)):\n",
    "    for team_id in (100, 200):\n",
    "        for lane in ('BOTTOM', 'MIDDLE', 'TOP', 'JUNGLE'):\n",
    "            for key in ('goldPerMinDeltas', 'creepsPerMinDeltas', 'xpPerMinDeltas', 'damageTakenPerMinDeltas'):\n",
    "                for frame in ('0-10',):\n",
    "                    yield (\n",
    "                        f\"{key}{team_to_text[team_id].title()}{lane.title()}{frame.split('-')[-1]}\",\n",
    "                        'f4',\n",
    "                        partial(_extract_participant_timeline_key, team_id, lane, key, frame)\n",
    "                    )\n",
    "        \n",
    "features = (\n",
    "    ('redWin', 'i1', extract_red_win),\n",
    "\n",
    "    ('firstDragon', 'i1', partial(_extract_indicator_from_teams, 'firstDragon')),\n",
    "    ('firstRiftHerald', 'i1', partial(_extract_indicator_from_teams, 'firstRiftHerald')),\n",
    "    \n",
    "    ('firstBlood', 'i1', partial(_extract_indicator_from_teams, 'firstBlood')),\n",
    "    ('anyFirstBloodAssist', 'i1', partial(_extract_participant_stat, any, 'firstBloodAssist')),\n",
    "    ('sumFirstBloodAssist', 'i1', partial(_extract_participant_stat, sum, 'firstBloodAssist')),\n",
    "\n",
    "    ('firstTower', 'i1', partial(_extract_indicator_from_teams, 'firstTower')),\n",
    "    ('anyFirstTowerAssist', 'i1', partial(_extract_participant_stat, any, 'firstTowerAssist')),\n",
    "    ('sumFirstTowerAssist', 'i1', partial(_extract_participant_stat, sum, 'firstTowerAssist'))\n",
    ")+tuple(\n",
    "    extractor for extractor in\n",
    "    generate_participant_timeline_extractors(\n",
    "        (100, 200),\n",
    "        ('BOTTOM', 'MIDDLE', 'TOP', 'JUNGLE'),\n",
    "        ('goldPerMinDeltas', 'creepsPerMinDeltas', 'xpPerMinDeltas', 'damageTakenPerMinDeltas'),\n",
    "        ('0-10',)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "The data is in a folder with one file per match. The files are JSON encoded and named `{matchID}.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = join(expanduser('~'), 'Downloads', 'lol_matches')\n",
    "\n",
    "filelist = listdir(base_path)[:1000]\n",
    "\n",
    "data = np.zeros(len(filelist), dtype=[(f, t) for f, t, _ in features])\n",
    "\n",
    "type_to_default = {'i1': -128, 'f4': np.nan}\n",
    "for f, t, _ in features:\n",
    "    data[f] = type_to_default[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"loading max. {len(filelist)} files\")\n",
    "\n",
    "def load_and_parse_match_details(data: np.ndarray, file_i: int, base_path: str, file_name: str):\n",
    "    file_path = join(base_path, file_name)\n",
    "\n",
    "    if isfile(file_path):\n",
    "        with open(file_path, 'r') as match_file:\n",
    "            match_details = load(match_file)\n",
    "            \n",
    "        if not match_details['queueId'] in (420, 440):\n",
    "            remove(file_path)\n",
    "        else:\n",
    "            for feature, _, extractor in features:\n",
    "                data[feature][file_i] = extractor(match_details)\n",
    "                \n",
    "    return file_i\n",
    "\n",
    "max_file_done = 0\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    \n",
    "    print(f\"using {executor._max_workers} threads\")\n",
    "\n",
    "    futures = tuple(\n",
    "        executor.submit(load_and_parse_match_details, data, file_i, base_path, file_name)\n",
    "        for file_i, file_name in enumerate(filelist)\n",
    "        if file_name.endswith('.json')\n",
    "    )\n",
    "    \n",
    "    print(f\"submitted all {len(futures)} to the executor\")\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            file_i = future.result()\n",
    "        except Exception as exception:\n",
    "            print(f\"error parsing files - {exception}\")\n",
    "        else:\n",
    "            max_file_done = max(max_file_done, file_i)\n",
    "            if file_i%1000 == 0 or max_file_done+1==len(filelist):\n",
    "                clear_output(wait=True)\n",
    "                display(f\"{100.0*float(max_file_done+1)/float(len(filelist)):>5.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove matches without first blood or first tower. These presumably were not played to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:][((data['firstBlood'] != 0) | (data['firstTower'] != 0))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any columns that only have one value. They provide no information at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = []\n",
    "for f, _, _ in features:\n",
    "    if (data[f] == data[f][0]).all():\n",
    "        drop_columns.append(f)\n",
    "\n",
    "data = data[tuple(f for f, _, _ in features if f not in drop_columns)].copy()\n",
    "features = tuple(f for f in features if f[0] not in drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = np.zeros((len(features), len(features)), dtype='float32')\n",
    "\n",
    "for f1_i, (f1, _, _) in enumerate(features):\n",
    "    for f2_i, (f2, _, _) in enumerate(features):\n",
    "        corr[f1_i, f2_i] = np.corrcoef(data[f1], data[f2])[0, 1]\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sb.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "_ = sb.heatmap(\n",
    "    corr, mask=mask, cmap=cmap, #vmax=.3,\n",
    "    linewidths=.5, cbar_kws={\"shrink\": .5},\n",
    "    ax=ax, annot=True,\n",
    "    xticklabels=tuple(f for f, _, _ in features),\n",
    "    yticklabels=tuple(f for f, _, _ in features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['sumFirstTowerAssist'] = (((data['sumFirstTowerAssist']*data['anyFirstTowerAssist'])+1)*data['anyFirstTowerAssist'])\n",
    "# data['sumFirstTowerAssist'] = (1.5 / (1 + np.exp(-data['sumFirstTowerAssist'])))-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as logistic_model:\n",
    "    pm.glm.GLM.from_formula(\n",
    "        'redWin ~ firstDragon + firstRiftHerald + firstBlood + firstTower + anyFirstTowerAssist + sumFirstTowerAssist',\n",
    "        data,\n",
    "        family=pm.glm.families.Binomial()\n",
    "    )\n",
    "    trace_logistic_model = pm.sample(2000, chains=None, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traces(traces, retain=1000):\n",
    "    '''\n",
    "    Convenience function:\n",
    "    Plot traces with overlaid means and values\n",
    "    '''\n",
    "\n",
    "    ax = pm.traceplot(traces[-retain:], figsize=(12,len(traces.varnames)*1.5),\n",
    "        lines={k: v['mean'] for k, v in pm.summary(traces[-retain:]).iterrows()})\n",
    "\n",
    "    for i, mn in enumerate(pm.summary(traces[-retain:])['mean']):\n",
    "        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n",
    "                    ,xytext=(5,10), textcoords='offset points', rotation=90\n",
    "                    ,va='bottom', fontsize='large', color='#AA0022')\n",
    "\n",
    "plot_traces(trace_logistic_model, retain=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
